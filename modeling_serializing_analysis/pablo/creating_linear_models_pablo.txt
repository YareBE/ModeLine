SCIKIT-LEARN
	Scikit-learn is a simple and user-friendly library for creating supervised and unsupervised machine learning models in Python. It is built on top 
	of NumPy, SciPy, and Matplotlib, which are core mathematical and scientific libraries in Python.
	On its official website, scikit-learn provides extensive documentation for all its functions, along with a “Getting Started” section, tutorials, 
	and practical examples — everything needed to learn and work efficiently with the library.
	
	Scikit-learn includes a wide range of preprocessing tools to prepare datasets. Among them are One-Hot Encoding and LabelEncoder, used to convert 
	categorical variables into numerical ones. It also offers feature selection methods such as RFE (Recursive Feature Elimination) and mutual 
	information (MI) to remove irrelevant or redundant columns.
	
	One of the reasons for choosing scikit-learn is its ability to handle missing values. The library provides multiple imputation strategies, such 
	as mean/median imputation, forward fill, and more advanced techniques. In addition, it includes numerous machine learning algorithms that allow 
	users to build complex models in a simple way, condensing large amounts of code into easy-to-use functions.
	
	In conclusion, scikit-learn offers all the necessary tools to preprocess, create, train, and evaluate models in Python, combining power, 
	flexibility, and ease of use.
	
	Example: Recognizing Handwritten Digits with Scikit-learn
	# Authors: The scikit-learn developers
	# SPDX-License-Identifier: BSD-3-Clause

	import matplotlib.pyplot as plt
	from sklearn import datasets, metrics, svm
	from sklearn.model_selection import train_test_split		

	# Load dataset
	digits = datasets.load_digits()

	# Display some training images
	_, axes = plt.subplots(1, 4, figsize=(10, 3))
	for ax, image, label in zip(axes, digits.images, digits.target):
	    ax.set_axis_off()
	    ax.imshow(image, cmap=plt.cm.gray_r, interpolation="nearest")
	    ax.set_title(f"Training: {label}")

	# Flatten the images
	n_samples = len(digits.images)
	data = digits.images.reshape((n_samples, -1))

	# Create a Support Vector Classifier
	clf = svm.SVC(gamma=0.001)

	# Split data into train and test sets
	X_train, X_test, y_train, y_test = train_test_split(
	    data, digits.target, test_size=0.5, shuffle=False
	)

	# Train the model
	clf.fit(X_train, y_train)

	# Make predictions
	predicted = clf.predict(X_test)

	# Display predictions
	_, axes = plt.subplots(1, 4, figsize=(10, 3))
	for ax, image, prediction in zip(axes, X_test, predicted):
	    ax.set_axis_off()
	    image = image.reshape(8, 8)
	    ax.imshow(image, cmap=plt.cm.gray_r, interpolation="nearest")
	    ax.set_title(f"Prediction: {prediction}")

	# Show classification results
	print(f"Classification report for classifier {clf}:\n"
	      f"{metrics.classification_report(y_test, predicted)}\n")

	# Display confusion matrix
	disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted)
	disp.figure_.suptitle("Confusion Matrix")
	print(f"Confusion matrix:\n{disp.confusion_matrix}")

	plt.show()


STATSMODEL:
	Statsmodels is a Python library focused on statistical modeling and inference. Its official documentation (statsmodels.org) is extense, featuring a 
	complete user guide, detailed API references, and numerous practical examples. It provides two main interfaces: an object-oriented one and a 
	formula-based one similar to R, making it accessible for both beginners and advanced users. The active community and external tutorials complement 
	the official materials. However, since Statsmodels emphasizes statistical interpretation over pure prediction, a basic understanding of statistics 
	is recommended to fully take advantage of its outputs.



	Creating a linear model in Statsmodels is very straightforward. You can write the formula directly, like ols("y ~ x1 + x2", data=df), like in R, 
	or use a more manual approach with a matrix-bases interface. If you use the second option, you would need to add a constant term to include the 
	intercept. After that, call .fit() to train the model and .summary() to see the results, which includes options to understand coefficients, 
	significance levels, and R². Statsmodels also supports other types of linear models, such as weighted or robust regression, but the basic process 
	stays the same: define the model, fit it, and review the summary.


	Simple example to illustrate how easy it is to fit and interpret a basic linear regression model using Statsmodels:

	import statsmodels.api as sm
	import statsmodels.formula.api as smf

	# Formula interface
	model = smf.ols("y ~ x1 + x2", data=df).fit()
	print(model.summary())

	# Matrix interface
	X = sm.add_constant(df[["x1", "x2"]])
	y = df["y"]

	model2 = sm.OLS(y, X).fit()
	print(model2.summary())
	
NumPy, Pandas, Matplotlib:
	Mathematical libraries such as pandas, NumPy, and Matplotlib are essential tools in the process of building linear models in Python.
	
	Pandas provides powerful data structures like DataFrames, allowing users to clean, organize, and manipulate datasets efficiently. 
	It simplifies tasks such as handling missing values, selecting variables, and preparing data for modeling.
	
	NumPy underpins much of the numerical computation in Python. It offers fast operations on large arrays and matrices, which are the 
	core of any linear model’s calculations. Most machine learning libraries, including scikit-learn and statsmodels, rely on NumPy for 
	data representation and mathematical efficiency.
	
	Matplotlib, on the other hand, is crucial for visualization. It helps plot data distributions, relationships between variables, and 
	model results such as regression lines or residuals.
	
	Together, these libraries form the foundation of data analysis and modeling workflows: pandas for data handling, NumPy for computation, 
	and Matplotlib for visualization. Without them, building, understanding, and evaluating linear models would be far more complex and less 
	efficient.




	
